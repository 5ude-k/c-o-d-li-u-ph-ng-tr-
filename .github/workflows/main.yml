name: Run Scraper

on:
  schedule:
    - cron: "0 17 * * *"   # âœ… 0h00 Viá»‡t Nam (UTC+7)
  workflow_dispatch:
  push:

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    permissions:
      contents: write   # Cho phÃ©p push file káº¿t quáº£

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 nbconvert jupyter pandas openpyxl sqlite3

      - name: Convert and run notebook
        run: |
          jupyter nbconvert --to python API.ipynb
          python API.py |& tee log.txt

      - name: Create SQLite database (.sql)
        run: |
          python - <<'EOF'
          import pandas as pd
          import sqlite3
          import os

          excel_file = "nhatot_phongtro_danang_all.xlsx"
          sql_file = "data.sql"

          if not os.path.exists(excel_file):
              print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {excel_file}")
              exit(1)

          print(f"ðŸ”„ Äang táº¡o {sql_file} tá»« {excel_file}...")
          df = pd.read_excel(excel_file)
          conn = sqlite3.connect(sql_file)
          df.to_sql("nhatot_phongtro_danang", conn, if_exists="replace", index=False)
          conn.close()
          print("âœ… ÄÃ£ táº¡o file data.sql thÃ nh cÃ´ng!")
          EOF

      - name: Commit scraped data + SQL
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git add nhatot_phongtro_danang_all.xlsx data.sql log.txt
          git commit -m "Auto scrape & SQL update $(date +'%Y-%m-%d %H:%M:%S')" || echo "No changes to commit"
          git push



